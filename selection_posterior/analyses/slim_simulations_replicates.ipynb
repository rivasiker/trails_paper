{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095295a5-dbf0-42a0-be6d-31f2271b1ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/au595587/opt/miniconda3/envs/trails_plot/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from trails.read_data import get_obs_state_dct\n",
    "import re\n",
    "from trails.cutpoints import cutpoints_ABC, cutpoints_AB\n",
    "from trails.optimizer import post_prob\n",
    "import msprime, tskit\n",
    "from trails.optimizer import post_prob_wrapper\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "n_sites = 200000\n",
    "# name = 'sim_45ILS_0.5sel'\n",
    "# name = '../results/sim_45ILS_nosel'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c56a4434-1f28-4b82-b67b-853c6aecba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mutations(dir_name, i):\n",
    "    \"\"\"\n",
    "    This function parses the SLiM output for a certain sample.\n",
    "    \"\"\"\n",
    "    # Save the mutations\n",
    "    with open(f'{dir_name}_{i}.log', 'r') as f:\n",
    "        mut = False\n",
    "        for line in f:\n",
    "            if line == 'Mutations:\\n':\n",
    "                mutations = []\n",
    "                mut = True\n",
    "            elif line == 'Genomes:\\n':\n",
    "                break\n",
    "            elif mut:\n",
    "                mutations.append(line.strip('\\n'))\n",
    "    l = [m.split(' ')+[i] for m in mutations]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb82250-4a29-49cf-b78c-501cce5b4a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slim_to_df(dir_name):\n",
    "    # Run the function for all samples\n",
    "    l_tot = []\n",
    "    for i in ['1', '2', '3', '4']:\n",
    "        l = mutations(dir_name, i)\n",
    "        l_tot = l_tot + l\n",
    "\n",
    "    # Make pandas data frame\n",
    "    df = pd.DataFrame(l_tot, \n",
    "                       columns = ['mut_id_sample', 'id', 'type', 'pos', 'sel', 'dom', 'pop', 'time', 'prev', 'sam'])\n",
    "    # Drop temporary mutation id\n",
    "    df = df.drop(['mut_id_sample'], axis=1)\n",
    "    # Calculate max time per position and sample, in case there are multiple mutations on the same position\n",
    "    df['max'] = df.groupby(['pos', 'sam'])['time'].transform(max)\n",
    "    # Only keep latest mutation\n",
    "    df = df[df['time'] == df['max']]\n",
    "    # Merge samples\n",
    "    df = df.groupby(['id', 'pos', 'time'])['sam'].apply(lambda x: ''.join(x)).reset_index()\n",
    "    # Get genotype\n",
    "    df['sam2'] = [''.join(['1' if str(y) in x else '0' for y in range(1, 5)]) for x in df['sam']]\n",
    "    # Change type\n",
    "    df = df.astype({\"id\":\"int\", \"pos\":\"int\"})\n",
    "    # Arrange values by time\n",
    "    df = df.sort_values('time')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca581db-5ae3-45ba-9aeb-740eec6e192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genotype(site, sam2): \n",
    "    \"\"\"\n",
    "    This function samples a random nt for a mutation\n",
    "    \"\"\"\n",
    "    nochange_lst = ['A', 'C', 'T', 'G']\n",
    "    nochange_lst.remove(site.upper())\n",
    "    geno1 = np.random.choice(nochange_lst, 1)[0]\n",
    "    g_mut = ''.join([site if j == '0' else geno1 for j in sam2])\n",
    "    return g_mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aa266f8-4ba8-43e6-91d9-80fa5aa87e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dfsim(df2, n_sites, seed):\n",
    "\n",
    "    # Simulate random genome\n",
    "    np.random.seed(seed); sim_genome = np.random.choice(['a', 'c', 't', 'g'], n_sites)\n",
    "\n",
    "    # Save ancestral allele\n",
    "    df2['geno'] = [sim_genome[i] for i in df2['pos']]\n",
    "    # Change genotype according to mutational pattern\n",
    "    np.random.seed(seed+1); df2['geno2'] = [genotype(variant[1]['geno'], variant[1]['sam2']) for variant in df2.iterrows()]\n",
    "    # Calculate how many mutations per site\n",
    "    df2['size'] = [list(df2['pos']).count(i) for i in df2['pos']]\n",
    "    df2 = df2.sort_values(['pos', 'time'])\n",
    "\n",
    "    return df2, sim_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661f2358-9146-4999-bf0c-0c8605799df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sam2(x):\n",
    "    \"\"\"\n",
    "    This function combines sam2 columns\n",
    "    \"\"\"\n",
    "    l = []\n",
    "    acc = 1\n",
    "    for i in x:\n",
    "        i = i.replace('1', str(acc))\n",
    "        l.append(i)\n",
    "        acc += 1\n",
    "    res = '0000'\n",
    "    for i in l:\n",
    "        for j in range(len(i)):\n",
    "            if i[j] != '0':\n",
    "                list1 = list(res)\n",
    "                list1[j] = i[j]\n",
    "                res = ''.join(list1)\n",
    "    return res\n",
    "\n",
    "def combine_geno2(x):\n",
    "    \"\"\"\n",
    "    This function combines geno2 columns\n",
    "    \"\"\"\n",
    "    acc = 1\n",
    "    for i in x:\n",
    "        for j in i:\n",
    "            if j in ['a', 'c', 't', 'g']:\n",
    "                low = j\n",
    "    res = low+low+low+low\n",
    "    for i in x:\n",
    "        for j in range(len(i)):\n",
    "            if i[j] != low:\n",
    "                list1 = list(res)\n",
    "                list1[j] = i[j]\n",
    "                res = ''.join(list1)\n",
    "    return res.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28dca0fd-59b8-45ec-83bd-d12fc8e59f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dfsim(df2, sim_genome):\n",
    "    df3 = df2.groupby(['pos']).agg(\n",
    "        {'id': 'max', \n",
    "         'time': 'max',\n",
    "         'sam': 'max',\n",
    "         'sam2': combine_sam2,\n",
    "         'geno': 'max',\n",
    "         'geno2': combine_geno2,\n",
    "         'size': 'max'\n",
    "        }).reset_index()\n",
    "\n",
    "    # Get dictionary from data frame\n",
    "    d = dict(zip(df3.pos, df3.geno2))\n",
    "    # Get ancestral genotype\n",
    "    sim_genome_upper = [i.upper()*4 for i in sim_genome]\n",
    "    # Add mutations at the right location\n",
    "    for i in list(d.keys()):\n",
    "        sim_genome_upper[i] = d[i]\n",
    "    lst_index = get_obs_state_dct()\n",
    "    sim_genome_idx = [lst_index.index(i) for i in sim_genome_upper]\n",
    "    return sim_genome_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bcc9ed4-d14d-4d9e-aaa4-da948d91dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(dir_name, n_sites, seed):\n",
    "    df = slim_to_df(dir_name)\n",
    "    df2, sim_genome = df_to_dfsim(df, n_sites, seed)\n",
    "    return clean_dfsim(df2, sim_genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7272fc7-d231-4d8e-b5a5-973d5aa97ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f21d1556-e787-4c2e-8236-8ce4ba97e988",
   "metadata": {},
   "source": [
    "## Second coalescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8e4437b-cdf7-4e89-9210-1d1eb1a08be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1293.58767003, 1347.54040797, 1411.35295285, 1489.45319581,\n",
       "       1590.14192117, 1732.05470901, 1974.6562222 ,           inf])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ILS = 32\n",
    "\n",
    "t_A = 200000/200\n",
    "t_B = 200000/200\n",
    "t_1 = max([t_A, t_B])\n",
    "N_AB = 80000/200\n",
    "t_2 = -N_AB*np.log(3/2*ILS/100)\n",
    "t_C = t_1+t_2\n",
    "N_ABC = 70000/200\n",
    "t_3 = t_1*5\n",
    "r = 0.5e-8*200\n",
    "mu = 1.5e-8*200\n",
    "\n",
    "# t_A = 1900\n",
    "# t_B = 1900\n",
    "# t_1 = max([t_A, t_B, t_C])\n",
    "# N_AB = 500\n",
    "# t_2 = t_1+t_2\n",
    "# t_C = 1900\n",
    "# N_ABC = 500\n",
    "# t_3 = 8000\n",
    "# r = 2e-6\n",
    "# mu = 0.5e-6\n",
    "\n",
    "n_int_AB = 5\n",
    "n_int_ABC = 7\n",
    "\n",
    "N_ref = N_ABC\n",
    "\n",
    "t_out = t_1+t_2+t_3+2*N_ABC\n",
    "\n",
    "coal_ABC = N_ref/N_ABC\n",
    "coal_AB = N_ref/N_AB\n",
    "t_upper = t_3-cutpoints_ABC(n_int_ABC, 1/N_ABC)[-2]\n",
    "t_AB = t_2/N_ref\n",
    "\n",
    "cut_AB = t_1+cutpoints_AB(n_int_AB, t_2, 1/N_AB)\n",
    "cut_ABC = t_1+t_2+cutpoints_ABC(n_int_ABC, 1/N_ABC)\n",
    "\n",
    "(2/3)*(np.exp(-t_2/(N_AB)))\n",
    "\n",
    "cut_ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91dea6e4-cdab-48dd-ae3c-651c9df5c6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: ‘PhaseTypeR’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:stats’:\n",
      "\n",
      "    var\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "✔ dplyr     1.1.2     ✔ readr     2.1.4\n",
      "✔ forcats   1.0.0     ✔ stringr   1.5.0\n",
      "✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n",
      "✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n",
      "✔ purrr     1.0.1     \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n"
     ]
    }
   ],
   "source": [
    "%%R -i t_2 -i N_AB -i n_int_ABC -o quant\n",
    "\n",
    "library(PhaseTypeR)\n",
    "library(tidyverse)\n",
    "\n",
    "subint_mat <- matrix(\n",
    "    c(\n",
    "        c(-1, 0, 0),\n",
    "        c(0, -3, 3),\n",
    "        c(0, 0, -1)\n",
    "    ),\n",
    "    nrow = 3,\n",
    "    byrow = T\n",
    ")\n",
    "init_probs <- c(1-exp(-t_2/N_AB), exp(-t_2/N_AB), 0)\n",
    "ph_obj <- PH(subint_mat, init_probs)\n",
    "\n",
    "quant <- qPH(seq(0, 1, length.out = n_int_ABC+1), ph_obj)\n",
    "quant <- c(quant[1:(length(quant)-1)], Inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74a5c0fa-456c-4db8-95ba-6ca3f5273619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1293.58767003, 1378.40193595, 1459.33047652, 1548.599671  ,\n",
       "       1656.82374396, 1803.65195797, 2049.04300645,           inf])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_ABC = t_1+t_2+quant*N_ABC\n",
    "\n",
    "cut_ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b55addd-7ffe-4cb1-b52d-c485bfd81cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 15:13:21,409\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "/Users/au595587/opt/miniconda3/envs/trails_plot/lib/python3.9/site-packages/trails/get_emission_prob_mat.py:632: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if cut_ABC == 'standard':\n"
     ]
    }
   ],
   "source": [
    "from trails.optimizer import trans_emiss_calc\n",
    "\n",
    "\n",
    "transitions, emissions, starting, hidden_states, observed_states = trans_emiss_calc(\n",
    "    t_A*mu, t_B*mu, t_C*mu, t_2*mu, t_upper*mu, t_out*mu, \n",
    "    N_AB*mu, N_ABC*mu, r/mu, n_int_AB, n_int_ABC, \n",
    "    cut_AB = 'standard', cut_ABC = quant)\n",
    "\n",
    "dct_hid = {v: k for k, v in hidden_states.items()}\n",
    "dct = {v: k for k, v in observed_states.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0417a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2043a11f-13bd-4872-bfb7-870a0ec22ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsim = 26\n",
    "\n",
    "name = f'../results/replicates/sim_45ILS_0.5sel_deep_{nsim}'\n",
    "\n",
    "sim_genome_idx = np.array(wrapper(name, n_sites, 1))\n",
    "sim_genome_idx\n",
    "\n",
    "ts = tskit.load(name+\".trees\")\n",
    "ts = ts.simplify()\n",
    "ts = ts.simplify(samples = [0, 2, 4, 6])\n",
    "\n",
    "t = ts.first()\n",
    "t_new = t.as_newick(include_branch_lengths=False)\n",
    "t_new\n",
    "\n",
    "##############\n",
    "\n",
    "left_lst = []\n",
    "right_lst = []\n",
    "tree_state = []\n",
    "t_AB_vec = []\n",
    "t_ABC_vec = []\n",
    "for t in ts.trees():\n",
    "    # Append start coordinate\n",
    "    left_lst.append(t.interval.left)\n",
    "    # Append end coordinate\n",
    "    right_lst.append(t.interval.right-1)\n",
    "    # Get all non-zero coalescent times\n",
    "    ntimes = [ts.nodes()[n].time for n in t.nodes() if ts.nodes()[n].time not in [0, t_1-t_A, t_1-t_B, t_1-t_C]]\n",
    "    ntimes = sorted(ntimes)\n",
    "    # Get time of the first event\n",
    "    mint = ntimes[0]\n",
    "    mint2 = ntimes[1]\n",
    "    # Find topology\n",
    "    find_re = re.findall(\"n\\d,n\\d\", t.as_newick(include_branch_lengths=False))[0]\n",
    "    # Sort species within topology\n",
    "    find_re = sorted(find_re.split(','))\n",
    "    # If V0 or V1\n",
    "    if find_re == ['n0', 'n1']:\n",
    "        # If the time of the first coalescent is larger than the deepest speciation event\n",
    "        if mint>=(t_1+t_2):\n",
    "            state = (1, (mint>=cut_ABC).sum()-1, (mint2>cut_ABC).sum()-1)\n",
    "            # Append V1 state\n",
    "        else:\n",
    "            state = (0, (mint>=cut_AB).sum()-1, (mint2>cut_ABC).sum()-1)\n",
    "            # Append V0 state\n",
    "    # If V2\n",
    "    elif find_re == ['n0', 'n2']:\n",
    "        state = (2, (mint>=cut_ABC).sum()-1, (mint2>cut_ABC).sum()-1)\n",
    "    # If V3\n",
    "    elif find_re == ['n1', 'n2']:\n",
    "        state = (3, (mint>=cut_ABC).sum()-1, (mint2>cut_ABC).sum()-1)\n",
    "    else:\n",
    "        state = (4, (mint>cut_ABC).sum()-1, (mint2>cut_ABC).sum()-1)\n",
    "    tree_state.append(state)\n",
    "    t_AB_vec.append(mint)\n",
    "    t_ABC_vec.append(mint2)\n",
    "\n",
    "##############\n",
    "\n",
    "tree_matrix = np.random.randint(max(left_lst), size=(len(left_lst), 3))\n",
    "tree_matrix[:,0] = left_lst\n",
    "tree_matrix[:,1] = right_lst\n",
    "# tree_state_corrected = [tuple(abs(i) for i in j) for j in tree_state]\n",
    "tree_matrix[:,2] = [dct_hid[i] for i in tree_state]\n",
    "\n",
    "##############\n",
    "\n",
    "hidden_matrix = np.random.randint(max([n_int_AB, n_int_ABC]), size=(len(dct_hid), 4))\n",
    "hidden_matrix[:,0] = list(range(len(dct_hid)))\n",
    "hidden_matrix[:,1] = [i[0] for i in dct_hid.keys()]\n",
    "hidden_matrix[:,2] = [i[1] for i in dct_hid.keys()]\n",
    "hidden_matrix[:,3] = [i[2] for i in dct_hid.keys()]\n",
    "\n",
    "##############\n",
    "\n",
    "post = post_prob_wrapper(transitions, emissions, starting, [sim_genome_idx])\n",
    "post_1 = post[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bcf0653-b1c5-4a79-985a-3e16f1038c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`summarise()` has grouped output by 'gr'. You can override using the `.groups`\n",
      "argument.\n"
     ]
    }
   ],
   "source": [
    "%%R -i post_1 -i hidden_matrix -i tree_matrix -i nsim\n",
    "\n",
    "library(tidyverse)\n",
    "\n",
    "hid_tab <- as_tibble(hidden_matrix) %>%\n",
    "    rename(name = V1, topology = V2, int_1 = V3, int_2 = V4)\n",
    "        \n",
    "tree_tab <- as_tibble(tree_matrix) %>%\n",
    "    rename(start = V1, end = V2, name = V3) %>%\n",
    "    mutate(\n",
    "        gr = ifelse(lag(name) != name, 1, 0) %>% coalesce(0),\n",
    "        gr = cumsum(gr) + 1\n",
    "    ) %>% \n",
    "    group_by(gr, name) %>%\n",
    "    summarize(start = min(start), end = max(end)) %>%\n",
    "    left_join(hid_tab, by = 'name')\n",
    "    \n",
    "post_tab <- as_tibble(post_1) %>%\n",
    "    mutate(pos = 0:(n()-1)) %>%\n",
    "    pivot_longer(-pos) %>%\n",
    "    mutate(name = as.integer(str_remove_all(name, 'V'))-1) %>%\n",
    "    left_join(hid_tab, by = 'name')\n",
    "\n",
    "write_csv(hid_tab, paste0('../results/replicates/hid_tab_second_', nsim, '.csv'))\n",
    "write_csv(tree_tab, paste0('../results/replicates/tree_tab_second_', nsim, '.csv'))\n",
    "write_csv(post_tab, paste0('../results/replicates/post_tab_second_', nsim, '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b110b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4803c9-31d6-4918-b6fd-c611561de495",
   "metadata": {},
   "source": [
    "## First coalescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfa1e201-c51f-487d-9a41-722ba174363a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1293.58767003, 1347.54040797, 1411.35295285, 1489.45319581,\n",
       "       1590.14192117, 1732.05470901, 1974.6562222 ,           inf])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ILS = 32\n",
    "\n",
    "t_A = 200000/200\n",
    "t_B = 200000/200\n",
    "t_1 = max([t_A, t_B])\n",
    "N_AB = 80000/200\n",
    "t_2 = -N_AB*np.log(3/2*ILS/100)\n",
    "t_C = t_1+t_2\n",
    "N_ABC = 70000/200\n",
    "t_3 = t_1*5\n",
    "r = 0.5e-8*200\n",
    "mu = 1.5e-8*200\n",
    "\n",
    "# t_A = 1900\n",
    "# t_B = 1900\n",
    "# t_1 = max([t_A, t_B, t_C])\n",
    "# N_AB = 500\n",
    "# t_2 = t_1+t_2\n",
    "# t_C = 1900\n",
    "# N_ABC = 500\n",
    "# t_3 = 8000\n",
    "# r = 2e-6\n",
    "# mu = 0.5e-6\n",
    "\n",
    "n_int_AB = 5\n",
    "n_int_ABC = 7\n",
    "\n",
    "N_ref = N_ABC\n",
    "\n",
    "t_out = t_1+t_2+t_3+2*N_ABC\n",
    "\n",
    "coal_ABC = N_ref/N_ABC\n",
    "coal_AB = N_ref/N_AB\n",
    "t_upper = t_3-cutpoints_ABC(n_int_ABC, 1/N_ABC)[-2]\n",
    "t_AB = t_2/N_ref\n",
    "\n",
    "cut_AB = t_1+cutpoints_AB(n_int_AB, t_2, 1/N_AB)\n",
    "cut_ABC = t_1+t_2+cutpoints_ABC(n_int_ABC, 1)*N_ABC\n",
    "\n",
    "(2/3)*(np.exp(-t_2/(N_AB)))\n",
    "\n",
    "cut_ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1d77325-af33-455f-8f06-17f8d30fee2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1293.58767003, 1311.57191601, 1332.8427643 , 1358.87617862,\n",
       "       1392.43908708, 1439.74334969, 1520.61052076,           inf])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant = cutpoints_ABC(n_int_ABC, 3)\n",
    "cut_ABC = t_1+t_2+quant*N_ABC\n",
    "cut_ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb4bfb1b-3827-4f2c-9156-b71a6918152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/au595587/opt/miniconda3/envs/phasetype/lib/python3.8/site-packages/trails/get_joint_prob_mat.py:151: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if cut_ABC == 'standard':\n",
      "\u001b[2m\u001b[36m(PoolActor pid=50736)\u001b[0m E0502 16:12:26.415494000 123145453637632 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(PoolActor pid=50735)\u001b[0m E0502 16:12:26.416144000 123145372639232 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(PoolActor pid=50731)\u001b[0m E0502 16:12:26.413347000 123145349758976 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(PoolActor pid=50738)\u001b[0m E0502 16:12:26.417100000 123145456160768 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "/Users/au595587/opt/miniconda3/envs/phasetype/lib/python3.8/site-packages/trails/get_emission_prob_mat.py:632: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if cut_ABC == 'standard':\n"
     ]
    }
   ],
   "source": [
    "from trails.optimizer import trans_emiss_calc\n",
    "\n",
    "\n",
    "transitions, emissions, starting, hidden_states, observed_states = trans_emiss_calc(\n",
    "    t_A*mu, t_B*mu, t_C*mu, t_2*mu, t_upper*mu, t_out*mu, \n",
    "    N_AB*mu, N_ABC*mu, r/mu, n_int_AB, n_int_ABC, \n",
    "    cut_AB = 'standard', cut_ABC = quant)\n",
    "\n",
    "dct_hid = {v: k for k, v in hidden_states.items()}\n",
    "dct = {v: k for k, v in observed_states.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c107e1e-c792-47bb-a878-df9dffc66db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_lst = []\n",
    "right_lst = []\n",
    "tree_state = []\n",
    "t_AB_vec = []\n",
    "t_ABC_vec = []\n",
    "for t in ts.trees():\n",
    "    # Append start coordinate\n",
    "    left_lst.append(t.interval.left)\n",
    "    # Append end coordinate\n",
    "    right_lst.append(t.interval.right-1)\n",
    "    # Get all non-zero coalescent times\n",
    "    ntimes = [ts.nodes()[n].time for n in t.nodes() if ts.nodes()[n].time not in [0, t_1-t_A, t_1-t_B, t_1-t_C]]\n",
    "    ntimes = sorted(ntimes)\n",
    "    # Get time of the first event\n",
    "    mint = ntimes[0]\n",
    "    mint2 = ntimes[1]\n",
    "    # Find topology\n",
    "    find_re = re.findall(\"n\\d,n\\d\", t.as_newick(include_branch_lengths=False))[0]\n",
    "    # Sort species within topology\n",
    "    find_re = sorted(find_re.split(','))\n",
    "    # If V0 or V1\n",
    "    if find_re == ['n0', 'n1']:\n",
    "        # If the time of the first coalescent is larger than the deepest speciation event\n",
    "        if mint>=(t_1+t_2):\n",
    "            state = (1, (mint>=cut_ABC).sum()-1, (mint2>cut_ABC).sum()-1)\n",
    "            # Append V1 state\n",
    "        else:\n",
    "            state = (0, (mint>=cut_AB).sum()-1, (mint2>cut_ABC).sum()-1)\n",
    "            # Append V0 state\n",
    "    # If V2\n",
    "    elif find_re == ['n0', 'n2']:\n",
    "        state = (2, (mint>=cut_ABC).sum()-1, (mint2>cut_ABC).sum()-1)\n",
    "    # If V3\n",
    "    elif find_re == ['n1', 'n2']:\n",
    "        state = (3, (mint>=cut_ABC).sum()-1, (mint2>cut_ABC).sum()-1)\n",
    "    else:\n",
    "        state = (4, (mint>cut_ABC).sum()-1, (mint2>cut_ABC).sum()-1)\n",
    "    tree_state.append(state)\n",
    "    t_AB_vec.append(mint)\n",
    "    t_ABC_vec.append(mint2)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f4f6673-10c2-4e59-b8c6-3ea64825db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_matrix = np.random.randint(max(left_lst), size=(len(left_lst), 3))\n",
    "tree_matrix[:,0] = left_lst\n",
    "tree_matrix[:,1] = right_lst\n",
    "# tree_state_corrected = [tuple(abs(i) for i in j) for j in tree_state]\n",
    "tree_matrix[:,2] = [dct_hid[i] for i in tree_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "602dd1b9-89ae-41d4-b63a-94c5a541f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_matrix = np.random.randint(max([n_int_AB, n_int_ABC]), size=(len(dct_hid), 4))\n",
    "hidden_matrix[:,0] = list(range(len(dct_hid)))\n",
    "hidden_matrix[:,1] = [i[0] for i in dct_hid.keys()]\n",
    "hidden_matrix[:,2] = [i[1] for i in dct_hid.keys()]\n",
    "hidden_matrix[:,3] = [i[2] for i in dct_hid.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be73e2c1-a6e4-4386-9a4a-02bc2f188996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trails.optimizer import post_prob_wrapper\n",
    "\n",
    "post = post_prob_wrapper(transitions, emissions, starting, [sim_genome_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb0c80b9-a464-4e70-8146-f51944bf4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_1 = post[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9bd7dbc-2958-4cac-a7e1-64d86d74a9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`summarise()` has grouped output by 'gr'. You can override using the `.groups` argument.\n"
     ]
    }
   ],
   "source": [
    "%%R -i post_1 -i hidden_matrix -i tree_matrix\n",
    "\n",
    "library(tidyverse)\n",
    "\n",
    "hid_tab <- as_tibble(hidden_matrix) %>%\n",
    "    rename(name = V1, topology = V2, int_1 = V3, int_2 = V4)\n",
    "        \n",
    "tree_tab <- as_tibble(tree_matrix) %>%\n",
    "    rename(start = V1, end = V2, name = V3) %>%\n",
    "    mutate(\n",
    "        gr = ifelse(lag(name) != name, 1, 0) %>% coalesce(0),\n",
    "        gr = cumsum(gr) + 1\n",
    "    ) %>% \n",
    "    group_by(gr, name) %>%\n",
    "    summarize(start = min(start), end = max(end)) %>%\n",
    "    left_join(hid_tab, by = 'name')\n",
    "    \n",
    "post_tab <- as_tibble(post_1) %>%\n",
    "    mutate(pos = 0:(n()-1)) %>%\n",
    "    pivot_longer(-pos) %>%\n",
    "    mutate(name = as.integer(str_remove_all(name, 'V'))-1) %>%\n",
    "    left_join(hid_tab, by = 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9630def-fc29-4d16-953d-5a150737c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "write_csv(hid_tab, '../results/hid_tab_first.csv')\n",
    "write_csv(tree_tab, '../results/tree_tab_first.csv')\n",
    "write_csv(post_tab, '../results/post_tab_first.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
